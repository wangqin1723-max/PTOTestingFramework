"""
Golden script generator for PTO testing framework.

Generates golden.py files compatible with simpler's CodeRunner.
"""

import inspect
import textwrap
from pathlib import Path
from typing import TYPE_CHECKING, List

if TYPE_CHECKING:
    from pto_test.core.test_case import PTOTestCase, TensorSpec


class GoldenGenerator:
    """Generates golden.py for simpler CodeRunner.

    The generated golden.py contains:
    - generate_inputs(params): Creates input/output numpy arrays
    - compute_golden(tensors, params): Computes expected outputs in-place
    - TENSOR_ORDER: List of tensor names in order
    - __outputs__: List of output tensor names
    - RTOL, ATOL: Comparison tolerances

    Example output:
        import numpy as np

        __outputs__ = ["c"]
        TENSOR_ORDER = ["a", "b", "c"]
        RTOL = 1e-5
        ATOL = 1e-5

        def generate_inputs(params):
            return {
                "a": np.full((128, 128), 2.0, dtype=np.float32),
                "b": np.full((128, 128), 3.0, dtype=np.float32),
                "c": np.zeros((128, 128), dtype=np.float32),
            }

        def compute_golden(tensors, params):
            tensors["c"][:] = tensors["a"] + tensors["b"]
    """

    def generate(self, test_case: "PTOTestCase") -> str:
        """Generate golden.py content from a test case.

        Args:
            test_case: The PTOTestCase to generate golden for.

        Returns:
            Python source code for golden.py.
        """
        tensor_specs = test_case.tensor_specs
        config = test_case.config

        # Get output names
        output_names = [t.name for t in tensor_specs if t.is_output]
        tensor_order = [t.name for t in tensor_specs]

        lines = [
            '"""',
            f'Auto-generated golden script for {test_case.get_name()}.',
            '',
            'Generated by pto_test.codegen.GoldenGenerator',
            '"""',
            '',
            'import numpy as np',
            '',
            f'__outputs__ = {output_names!r}',
            f'TENSOR_ORDER = {tensor_order!r}',
            f'RTOL = {config.rtol}',
            f'ATOL = {config.atol}',
            '',
        ]

        # Generate generate_inputs function
        lines.append('def generate_inputs(params):')
        lines.append('    """Generate input and output tensors."""')
        lines.append('    return {')

        for spec in tensor_specs:
            init_code = self._generate_init_code(spec)
            lines.append(f'        "{spec.name}": {init_code},')

        lines.append('    }')
        lines.append('')

        # Generate compute_golden function by extracting compute_expected source
        lines.append('')
        compute_golden_code = self._generate_compute_golden(test_case)
        lines.extend(compute_golden_code.split('\n'))
        lines.append('')

        return '\n'.join(lines)

    def _generate_init_code(self, spec: "TensorSpec") -> str:
        """Generate numpy initialization code for a tensor spec."""
        import numpy as np

        dtype_str = self._dtype_to_numpy_str(spec.dtype)
        shape_str = repr(tuple(spec.shape))

        if spec.is_output:
            # Outputs are zero-initialized
            return f'np.zeros({shape_str}, dtype={dtype_str})'
        elif spec.init_value is None:
            return f'np.zeros({shape_str}, dtype={dtype_str})'
        elif isinstance(spec.init_value, (int, float)):
            return f'np.full({shape_str}, {spec.init_value!r}, dtype={dtype_str})'
        elif callable(spec.init_value):
            # For callable initializers, generate random data
            # Note: This won't reproduce the exact same data, user should
            # use explicit values for reproducible tests
            return f'np.random.randn(*{shape_str}).astype({dtype_str})'
        elif isinstance(spec.init_value, np.ndarray):
            # Handle numpy array by detecting common patterns
            arr = spec.init_value

            # Check if all elements are the same (constant array)
            if arr.size > 0 and np.all(arr == arr.flat[0]):
                constant_val = arr.flat[0]
                if constant_val == 0:
                    return f'np.zeros({shape_str}, dtype={dtype_str})'
                elif constant_val == 1:
                    return f'np.ones({shape_str}, dtype={dtype_str})'
                else:
                    return f'np.full({shape_str}, {constant_val!r}, dtype={dtype_str})'

            # Check for identity matrix
            if len(arr.shape) == 2 and arr.shape[0] == arr.shape[1]:
                if np.allclose(arr, np.eye(arr.shape[0])):
                    return f'np.eye({arr.shape[0]}, dtype={dtype_str})'

            # For small arrays (< 100 elements), serialize directly
            if arr.size <= 100:
                # Convert array to Python list for serialization
                arr_list = arr.tolist()
                return f'np.array({arr_list!r}, dtype={dtype_str})'

            # For larger arrays, suggest using callable or saving to file
            return (f'np.zeros({shape_str}, dtype={dtype_str})  '
                   f'# Warning: Array too large ({arr.size} elements) to serialize. '
                   f'Consider using callable init_value or loading from file.')
        else:
            # Assume it's array-like
            return f'np.zeros({shape_str}, dtype={dtype_str})  # TODO: handle array init'

    def _dtype_to_numpy_str(self, dtype) -> str:
        """Convert DataType enum to numpy dtype string."""
        from pto_test.core.test_case import DataType

        mapping = {
            DataType.FP32: 'np.float32',
            DataType.FP16: 'np.float16',
            DataType.INT32: 'np.int32',
            DataType.INT64: 'np.int64',
            DataType.BOOL: 'np.bool_',
        }
        return mapping.get(dtype, 'np.float32')

    def _generate_compute_golden(self, test_case: "PTOTestCase") -> str:
        """Generate compute_golden function from compute_expected source.

        Extracts the compute_expected method source and renames it to compute_golden.
        Since both methods have the same signature now (tensors, params), we just
        need to rename the function and remove one level of indentation.

        Args:
            test_case: The PTOTestCase containing compute_expected method.

        Returns:
            Source code for compute_golden function.
        """
        try:
            # Get the source code of compute_expected
            source = inspect.getsource(test_case.compute_expected)

            # Replace method name and remove 'self' parameter
            lines = source.split('\n')
            result_lines = []

            for line in lines:
                if 'def compute_expected' in line:
                    # Replace method signature with standalone function
                    # Original: def compute_expected(self, tensors: Dict[str, np.ndarray], params: Optional[Dict[str, Any]] = None) -> None:
                    # New: def compute_golden(tensors, params):
                    # We'll do a simple replacement to handle various formatting
                    new_line = line.replace('def compute_expected(self, ', 'def compute_golden(')
                    # Remove type hints and return type annotation for simplicity
                    if ':' in new_line and '->' in new_line:
                        # Remove return type annotation
                        new_line = new_line.split('->')[0].rstrip() + ':'
                    # Remove one level of indentation (convert method to function)
                    if new_line.startswith('    '):
                        new_line = new_line[4:]
                    result_lines.append(new_line)
                else:
                    # Remove one level of indentation for all other lines
                    if line.startswith('    '):
                        result_lines.append(line[4:])
                    else:
                        result_lines.append(line)

            return '\n'.join(result_lines)

        except (TypeError, OSError):
            # Fallback: generate a placeholder
            output_specs = test_case.get_output_tensors()
            lines = [
                'def compute_golden(tensors, params):',
                '    """Compute expected outputs - PLACEHOLDER."""',
                '    # TODO: Could not extract compute_expected source.',
                '    # Please implement the expected computation here.',
            ]
            for spec in output_specs:
                lines.append(f'    # tensors["{spec.name}"][:] = ...')
            lines.append('')
            lines.append('    raise NotImplementedError("compute_expected source extraction failed")')
            return '\n'.join(lines)

    def write(self, test_case: "PTOTestCase", output_path: Path) -> Path:
        """Generate and write golden.py.

        Args:
            test_case: The PTOTestCase to generate golden for.
            output_path: Path to write golden.py.

        Returns:
            Path to the written golden.py file.
        """
        content = self.generate(test_case)
        output_path = Path(output_path)
        output_path.write_text(content)
        return output_path


class InlineGoldenGenerator(GoldenGenerator):
    """Golden generator that inlines the compute_expected logic.

    This generator creates a golden.py that directly calls back
    to the test case's compute_expected method. This is useful
    when the computation is complex and cannot be easily inlined.
    """

    def generate_with_callback(
        self,
        test_case: "PTOTestCase",
        compute_code: str,
    ) -> str:
        """Generate golden.py with explicit compute code.

        Args:
            test_case: The PTOTestCase.
            compute_code: Python code string for computing expected outputs.
                         Should modify tensors dict in-place.

        Returns:
            Python source code for golden.py.
        """
        tensor_specs = test_case.tensor_specs
        config = test_case.config

        output_names = [t.name for t in tensor_specs if t.is_output]
        tensor_order = [t.name for t in tensor_specs]

        lines = [
            '"""',
            f'Golden script for {test_case.get_name()}.',
            '"""',
            '',
            'import numpy as np',
            '',
            f'__outputs__ = {output_names!r}',
            f'TENSOR_ORDER = {tensor_order!r}',
            f'RTOL = {config.rtol}',
            f'ATOL = {config.atol}',
            '',
        ]

        # Generate generate_inputs
        lines.append('def generate_inputs(params):')
        lines.append('    return {')
        for spec in tensor_specs:
            init_code = self._generate_init_code(spec)
            lines.append(f'        "{spec.name}": {init_code},')
        lines.append('    }')
        lines.append('')

        # Generate compute_golden with provided code
        lines.append('')
        lines.append('def compute_golden(tensors, params):')
        # Indent the provided compute code
        indented_code = textwrap.indent(compute_code.strip(), '    ')
        lines.append(indented_code)
        lines.append('')

        return '\n'.join(lines)
